{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import (\n",
    "    KBinsDiscretizer,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tp-2020-2c-train-cols2.csv')\n",
    "targets = pd.read_csv('tp-2020-2c-train-cols1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.merge(left=data, right=targets, how=\"left\", on=\"id_usuario\", validate=\"one_to_one\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 801 entries, 0 to 800\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   tipo_de_sala   801 non-null    object \n",
      " 1   nombre         801 non-null    object \n",
      " 2   id_usuario     801 non-null    int64  \n",
      " 3   genero         801 non-null    object \n",
      " 4   edad           641 non-null    float64\n",
      " 5   amigos         801 non-null    int64  \n",
      " 6   parientes      801 non-null    int64  \n",
      " 7   id_ticket      801 non-null    object \n",
      " 8   precio_ticket  801 non-null    int64  \n",
      " 9   fila           177 non-null    object \n",
      " 10  nombre_sede    799 non-null    object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 69.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipo_de_sala       0\n",
       "nombre             0\n",
       "id_usuario         0\n",
       "genero             0\n",
       "edad             160\n",
       "amigos             0\n",
       "parientes          0\n",
       "id_ticket          0\n",
       "precio_ticket      0\n",
       "fila             624\n",
       "nombre_sede        2\n",
       "volveria           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_params = {'onehot_drop':'first'\n",
    "                  }\n",
    "scaling_params = {'standard_withmean':False}\n",
    "selection_params = {'vt_threshold':0,\n",
    "                    'rfe_estimator':'estimator'}\n",
    "\n",
    "columnas_a_encodear = ['tipo_de_sala', 'genero', 'nombre_sede']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "def OrdinalEncoderWrapper(encoding_params):\n",
    "    return OrdinalEncoder()\n",
    "\n",
    "def OneHotWrapper(encoding_params):\n",
    "    return OneHotEncoder(drop=encoding_params['onehot_drop'])\n",
    "\n",
    "def LabelEncoderWrapper(encoding_params):\n",
    "    return LabelEncoder()\n",
    "\n",
    "encoders = {'ordinal': OrdinalEncoderWrapper(encoding_params),\n",
    "           'label': LabelEncoderWrapper(encoding_params),\n",
    "            'onehot': OneHotWrapper(encoding_params)\n",
    "           }\n",
    "\n",
    "#scalers\n",
    "def StandardScalerWrapper(scaling_params):\n",
    "    return StandardScaler(with_mean=scaling_params['standard_withmean'])\n",
    "\n",
    "def MinMaxScalerWrapper(scaling_params):\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def RobustScalerWrapper(scaling_params):\n",
    "    return RobustScaler()\n",
    "\n",
    "def PowerTransformerWrapper(scaling_params):\n",
    "    return PowerTransformer()\n",
    "\n",
    "def NormalizerWrapper(scaling_params):\n",
    "    return Normalizer()\n",
    "\n",
    "scalers = {'standard': StandardScalerWrapper(scaling_params),\n",
    "          'minmax': MinMaxScalerWrapper(scaling_params),\n",
    "          'robust': RobustScalerWrapper(scaling_params),\n",
    "           'power' : PowerTransformerWrapper(scaling_params),\n",
    "           'normalizer' : NormalizerWrapper(scaling_params)\n",
    "          }\n",
    "\n",
    "#Selectors\n",
    "\n",
    "\n",
    "def VarianceThresholdWrapper(selection_params):\n",
    "    return VarianceThreshold()\n",
    "\n",
    "def RFEWrapper(selection_params):\n",
    "    return RFE(selection_params['rfe_estimator'])\n",
    "\n",
    "def FeatureHasherWrapper(selection_params):\n",
    "    return FeatureHasher()\n",
    "\n",
    "\n",
    "selectors = {'var_thres': VarianceThresholdWrapper(selection_params),\n",
    "            'rfe': RFEWrapper(selection_params),\n",
    "            'feature_hasher': FeatureHasherWrapper(selection_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones auxiliares\n",
    "#robado de la practica\n",
    "def droppear_nulos_por_columna(data):\n",
    "    NULL_REMOVE_PCT = 0.30\n",
    "    cols = data.isna().mean()\n",
    "    cols = cols[cols < NULL_REMOVE_PCT]\n",
    "    return data[cols.index]\n",
    "\n",
    "def droppear_filas_sin_sede(data):\n",
    "    _data = data.drop(data.loc[data['nombre_sede'].isna()].index, inplace=False)\n",
    "    _data.reset_index(drop=True)\n",
    "    return _data\n",
    "    \n",
    "\n",
    "def prepro_1(X, y, encoder, scaler, selector):\n",
    "    _X = X.copy(deep=True)\n",
    "    _y = y.copy(deep=True)\n",
    "    \n",
    "    #tratamiento de nulos\n",
    "    _X = droppear_nulos_por_columna(_X)\n",
    "    #_X = droppear_filas_sin_sede(_X) rompe el dataframe, no se por que\n",
    "    _X.drop(['id_ticket','nombre','id_usuario'], axis=1, inplace=True)\n",
    "    _X['edad'] = SimpleImputer(strategy='mean').fit_transform(_X[['edad']])\n",
    "    \n",
    "    \n",
    "    #encoding\n",
    "    _encoder = encoders[encoder]\n",
    "    if(encoder == 'onehot'):\n",
    "        for col in columnas_a_encodear:\n",
    "            \n",
    "            encoded = _encoder.fit(_X[[col]].astype(str))\n",
    "            categories = list(encoded.categories_)\n",
    "            encoded = encoded.transform(_X[[col]].astype(str)).todense().astype(int)\n",
    "            encoded = pd.DataFrame(encoded)\n",
    "            categories = np.delete(categories, 0)\n",
    "            encoded.columns = categories\n",
    "            \n",
    "            _X = pd.concat([_X, encoded], axis=1)\n",
    "            _X.drop(labels=col, axis=1, inplace=True)\n",
    "    \n",
    "    #seleccion\n",
    "    _selector = selectors[selector]\n",
    "    #_X = _selector.fit_transform(_X,_y)\n",
    "    \n",
    "    #escalado\n",
    "    _scaler = scalers[scaler]\n",
    "    _X = _scaler.fit_transform(_X, _y)\n",
    "    \n",
    "    _y = y['volveria'].to_numpy(copy=True)\n",
    "    \n",
    "    return _X, _y #pd.DataFrame(_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88062327, 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.39683338, 0.125     , 0.16666667, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.36778559, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.43453129, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36778559, 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.36778559, 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X, df_y = prepro_1(data, targets, 'onehot', 'minmax', 'var_thres')\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_X, df_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento con valores por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8423236514522822"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = neighbors.KNeighborsClassifier()\n",
    "clf_knn.fit(X_train, y_train)\n",
    "pred = clf_knn.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busqueda de hiperparámetros mediante GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_params = {\n",
    "    'n_neighbors': [3,5,11,19],\n",
    "    'weights' : ['distance', 'uniform'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    clf_knn,\n",
    "    knn_grid_params,\n",
    "    verbose = 3,\n",
    "    cv = 3,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810802522377475"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=19)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087, 0.7875   , 0.83125  , 0.8125   , 0.8125   ])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf_knn, df_X, df_y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6473029045643154"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb_gauss = naive_bayes.GaussianNB()\n",
    "clf_nb_gauss.fit(X_train, y_train)\n",
    "pred = clf_nb_gauss.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551867219917012"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mult_alpha = 1.0\n",
    "clf_nb_mult = naive_bayes.MultinomialNB()\n",
    "clf_nb_mult.fit(X_train, y_train)\n",
    "pred = clf_nb_mult.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Complemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510373443983402"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_comp_alpha = 1.0\n",
    "clf_nb_comp = naive_bayes.ComplementNB()\n",
    "clf_nb_comp.fit(X_train, y_train)\n",
    "pred = clf_nb_comp.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entendemos que como los datos no siguen una distribucion bernoulli multivariada, el metodo no aplica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Comun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento con valores por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8506224066390041"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = svm.SVC()\n",
    "clf_svc.fit(X_train, y_train)\n",
    "pred = clf_svc.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busqueda de hiperparametros mediante GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid_params = {\n",
    "    'kernel': ['rbf','linear'],\n",
    "    'C' : [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    clf_svc,\n",
    "    svc_grid_params,\n",
    "    verbose = 3,\n",
    "    cv = 3,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143196672608437"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77018634, 0.825     , 0.85625   , 0.825     , 0.825     ])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf_svc, df_X, df_y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174273858921162"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linear_svc = svm.LinearSVC()\n",
    "clf_linear_svc.fit(X_train, y_train)\n",
    "pred = clf_linear_svc.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087, 0.79375  , 0.8375   , 0.8      , 0.8      ])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf_linear_svc, df_X, df_y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Regresor Lineal (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train, y_train)\n",
    "pred = clf_logreg.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf_logreg, df_X, df_y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215767634854771"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "pred = clf_tree.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087, 0.75625  , 0.825    , 0.7625   , 0.79375  ])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf_tree, df_X, df_y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.1 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340248962655602"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = ensemble.RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "pred = random_forest.predict(X_test)\n",
    "score = (y_test == pred)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.2 Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
